{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28287a3",
   "metadata": {},
   "source": [
    "# LLM OpenAI Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d309fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9dfa1b1",
   "metadata": {},
   "source": [
    "# Minimalbeispiel: OpenAI LLM aus Python\n",
    "\n",
    "**Schritte**:\n",
    "1. API Key besorgen (OpenAI Dashboard) und als Umgebungsvariable setzen.\n",
    "   - PowerShell (nur aktuelle Sitzung): `$env:OPENAI_API_KEY = \"sk-...\"`\n",
    "   - Dauerhaft (Benutzer): `[Environment]::SetEnvironmentVariable(\"OPENAI_API_KEY\",\"sk-...\",\"User\")`\n",
    "2. Paket `openai` installieren (siehe nächste Zelle).\n",
    "3. Code-Zelle ausführen, Antwort erscheint unter der Zelle.\n",
    "\n",
    "**Hinweis**: Der Key darf nicht öffentlich geteilt werden. Wenn keine Umgebungsvariable gesetzt ist, fragt der Code interaktiv nach dem Key.\n",
    "\n",
    "**Modelle**: Für ein günstiges Beispiel wird `gpt-4.1-mini` verwendet (anpassbar).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54cb0b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installation des OpenAI Python Pakets\n",
    "!python -m pip install --quiet --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6604db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "# API Key laden oder abfragen\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass(\"OpenAI API Key eingeben: \")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt = \"Schreibe einen einzigen kurzen Satz über Computer Vision auf Deutsch.\"\n",
    "# Neues Responses-API (empfohlen)\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt,\n",
    ")\n",
    "\n",
    "# Ausgabe robuster extrahieren (Responses oder ältere Chat-Struktur)\n",
    "text = None\n",
    "try:\n",
    "    # Neues Schema\n",
    "    text = resp.output[0].content[0].text\n",
    "except Exception:\n",
    "    try:\n",
    "        # Fallback auf Chat Completion Struktur\n",
    "        text = resp.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        text = f\"Konnte Text nicht extrahieren: {e}\"\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7ac36",
   "metadata": {},
   "source": [
    "# Interaktiver Chat mit Verlauf (Responses API)\n",
    "\n",
    "- Führe diese Zelle und danach die nächste Code-Zelle aus.\n",
    "- In der Chat-Zelle kannst du Nachrichten eingeben; mit `exit`/`quit` beendest du.\n",
    "- API-Key wird aus `OPENAI_API_KEY`, aus der Datei `openai_api_key.txt` (im aktuellen Ordner) oder interaktiv abgefragt.\n",
    "- Modell ist per Variable anpassbar (Standard: `gpt-4.1-mini`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI Client erstellen (ENV > Datei > Eingabe)\n",
    "def get_openai_client():\n",
    "    key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not key and os.path.exists(\"openai_api_key.txt\"):\n",
    "        with open(\"openai_api_key.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            key = f.read().strip()\n",
    "    if not key:\n",
    "        key = getpass.getpass(\"OpenAI API Key eingeben: \")\n",
    "    return OpenAI(api_key=key)\n",
    "\n",
    "client = get_openai_client()\n",
    "model = \"gpt-4.1-mini\"  # anpassbar, z.B. \"gpt-4o-mini\"\n",
    "\n",
    "history = []  # Verlauf im Chat-Format: [{role, content}, ...]\n",
    "print(\"Chat gestartet. Tippe 'exit' zum Beenden.\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"Du> \").strip()\n",
    "    except EOFError:\n",
    "        break\n",
    "    if not user_input:\n",
    "        continue\n",
    "    if user_input.lower() in (\"exit\", \"quit\", \"q\"):\n",
    "        break\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    try:\n",
    "        # Responses API mit Chat-Verlauf\n",
    "        response = client.responses.create(\n",
    "            model=model,\n",
    "            input=history,\n",
    "        )\n",
    "        try:\n",
    "            bot_text = response.output_text  # praktischer Shortcut, falls verfügbar\n",
    "        except Exception:\n",
    "            # Fallback auf strukturierte Felder\n",
    "            try:\n",
    "                bot_text = response.output[0].content[0].text\n",
    "            except Exception as e:\n",
    "                bot_text = f\"Konnte Text nicht extrahieren: {e}\"\n",
    "    except Exception as e:\n",
    "        bot_text = f\"API-Fehler: {e}\"\n",
    "\n",
    "    history.append({\"role\": \"assistant\", \"content\": bot_text})\n",
    "\n",
    "    print(f\"Bot> {bot_text}\\n\")\n",
    "\n",
    "print(\"\\nVerlauf (JSON):\")\n",
    "print(\"-\"*60)\n",
    "print(json.dumps(history, ensure_ascii=False, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945810d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf425d8",
   "metadata": {},
   "source": [
    "# Multi Layer Perzeptron (MLP)\n",
    "\n",
    "Dieses Notebook zeigt die Implementierung und Visualisierung eines Multi Layer Perzeptrons (MLP) zur Klassifikation des MNIST-Datensatzes mit PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and print the training dataset\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dtatset:\\n\", train_dataset)\n",
    "\n",
    "# Create and print the validating dataset\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the validating dataset:\\n \", validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple training data\n",
    "h = plt.figure(figsize=(10,8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols*rows+1):\n",
    "    random_idx = torch.randint(len(train_dataset), size=(1,)).item() \n",
    "    img, label = train_dataset[random_idx]\n",
    "    h.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a86156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Multi Layer Perceptron (MLP) class\n",
    "class MLP(nn.Module):\n",
    "    # Contructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        pred = self.out(x)\n",
    "        return pred\n",
    "\n",
    "input_dim = 28*28\n",
    "hidden_dim = 32 # 130 512\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU if device is possible\n",
    "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device !=\"cuda\":\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Create Model\n",
    "model = MLP(input_dim, hidden_dim, output_dim).to(device)\n",
    "print('The model: \\n', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d18e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to plot weights\n",
    "def PlotParameters(model, hiddenDim): \n",
    "    W = model.state_dict()['hidden.0.weight'].data.cpu()\n",
    "    b = model.state_dict()['hidden.0.bias'].data.cpu()\n",
    "    w_min = W.min().item()\n",
    "    w_max = W.max().item()\n",
    "    fig, axes = plt.subplots(int(np.ceil(hiddenDim/10.0)), 10, figsize=(20,int(hiddenDim/10)*3))\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < hiddenDim:\n",
    "            ax.set_xlabel(f\"neuron: {i}\")\n",
    "            Img = W[i, :].view(28, 28)\n",
    "            ax.imshow(Img, vmin=-1, vmax=1, cmap='seismic')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "PlotParameters(model=model, hiddenDim = hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the learning_rate, optimizer, criterion and data loader\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#learning_rate = 0.1\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True, num_workers=1)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4aee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(dataloader, model, loss_func, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batchNr, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X.view(-1, input_dim))\n",
    "        loss = loss_func(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, yhat = torch.max(pred.data, 1)\n",
    "        correct += (yhat == y).sum().item()\n",
    "        train_loss += loss\n",
    "        if (batchNr+1) %100 == 0:\n",
    "            loss, current = loss.item(), (batchNr+1)*len(y)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "    accuracy = correct / size\n",
    "    train_accuracy_list.append(accuracy)\n",
    "    loss_list.append(train_loss.item()/size)\n",
    "\n",
    "# Validation function\n",
    "def validate(dataloader, model, loss_func):\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in dataloader:\n",
    "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "            pred = model(x_test.view(-1, input_dim))\n",
    "            val_loss += loss_func(pred, y_test)\n",
    "            _, yhat = torch.max(pred.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "    val_loss /= num_batches  \n",
    "    accuracy = correct / size\n",
    "    val_accuracy_list.append(accuracy)\n",
    "    val_loss_list.append(val_loss.item())\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*accuracy):>0.1f} Avg loss: {(val_loss.item()):>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aff6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 15\n",
    "loss_list = []\n",
    "train_accuracy_list = []\n",
    "val_loss_list = []\n",
    "val_accuracy_list = []\n",
    "N_train = len(train_dataset)\n",
    "N_test = len(validation_dataset)\n",
    "print(N_test)\n",
    "print(len(train_loader.dataset))\n",
    "\n",
    "for t in range(n_epochs):\n",
    "    print(f\"n_epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_func, optimizer)\n",
    "    validate(validation_loader, model, loss_func)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b086814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(loss_list,color=color)\n",
    "ax1.set_xlabel('epoch',color=color)\n",
    "ax1.set_ylabel('total loss',color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  \n",
    "ax2.plot( train_accuracy_list, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax2.plot(val_accuracy_list, color=color)\n",
    "\n",
    "color = 'tab:purple'\n",
    "ax2.plot(val_loss_list, color=color)\n",
    "\n",
    "PlotParameters(model, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().squeeze(), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n",
    "\n",
    "Softmax_fn=nn.Softmax(dim=1)\n",
    "\n",
    "count = 0\n",
    "for X, y in validation_dataset:\n",
    "    X = X.to(device)\n",
    "    y = torch.from_numpy(np.array([[y]]))\n",
    "    y = y.to(device)\n",
    "    z = model(X.reshape(-1, input_dim))\n",
    "    _, yhat = torch.max(z, 1)\n",
    "    yhat = int(yhat.item())\n",
    "    if yhat != y:\n",
    "        X, y = X.cpu(), y.cpu()\n",
    "        show_data((X, y.item()))\n",
    "        plt.show()\n",
    "        print(\"yhat:\", yhat)\n",
    "        print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n",
    "        count += 1\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = validation_dataset[63]\n",
    "X = X.to(device)\n",
    "y = torch.from_numpy(np.array([[y]]))\n",
    "y = y.to(device)\n",
    "z = model(X.reshape(-1, input_dim))\n",
    "_, yhat = torch.max(z, 1)\n",
    "yhat = int(yhat.item())\n",
    "X, y = X.cpu(), y.cpu()\n",
    "show_data((X, y.item()))\n",
    "plt.show()\n",
    "print(\"yhat:\", yhat)\n",
    "print(\"z:\", z)\n",
    "print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n",
    "print(X.shape)\n",
    "X = X.reshape(-1, input_dim)\n",
    "print(X.shape)\n",
    "hidden_out = model.hidden(X.to(device))\n",
    "\n",
    "print(hidden_out)\n",
    "\n",
    "b = model.state_dict()['hidden.0.bias'].data.cpu()\n",
    "reconstrWeights = hidden_out.data.cpu()\n",
    "min, max = reconstrWeights.min(), reconstrWeights.max()\n",
    "print(f'{min=} {max=}')\n",
    "\n",
    "W = model.state_dict()['hidden.0.weight'].data.cpu()\n",
    "Img = torch.zeros((28, 28))\n",
    "for i in range(hidden_dim):\n",
    "    s = reconstrWeights[:,i]\n",
    "    Mat = W[i, :].view(28, 28)\n",
    "    Mat = s*Mat\n",
    "    Img += Mat\n",
    "plt.imshow(Img, cmap='seismic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classValues = model.out(hidden_out)\n",
    "print(f'{classValues=}')\n",
    "\n",
    "Softmax_fn(classValues)\n",
    "\n",
    "W_out = model.state_dict()['out.weight'].data.cpu()\n",
    "b_out = model.state_dict()['out.bias'].data.cpu()\n",
    "print(W_out)\n",
    "print(W_out[3,:])\n",
    "\n",
    "def PlotOutputLayer(model, hiddenDim, outDim): \n",
    "    W = model.state_dict()['hidden.0.weight'].data.cpu()\n",
    "    W_out = model.state_dict()['out.weight'].data.cpu()\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20, 3))\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < outDim:\n",
    "            ax.set_xlabel(f\"neuron: {i}\")\n",
    "            classWeights = W_out[i, :] \n",
    "            Img = torch.zeros((28,28))\n",
    "            for j in range(hiddenDim):\n",
    "                s = classWeights[j]\n",
    "                Mat = W[j, :].view(28, 28)\n",
    "                Mat = s*Mat\n",
    "                Img += Mat\n",
    "            ax.imshow(Img, vmin=-1, vmax=1, cmap='seismic')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "PlotParameters(model, hidden_dim)\n",
    "PlotOutputLayer(model, hidden_dim, output_dim)\n",
    "\n",
    "hidden_out.data.cpu()\n",
    "\n",
    "W_out = model.state_dict()['out.weight'].data.cpu()\n",
    "print(W_out[3,:])\n",
    "print(W_out[3,:]*hidden_out.data.cpu())\n",
    "Softmax_fn(torch.matmul(hidden_out.data.cpu(), torch.transpose(W_out,0,1)) +  b_out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "CSV_FILE = \"./dataset/Cards-Image/cards.csv\"\n",
    "DATA_DIR = './dataset/Cards-Image/'\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "queen_of_hearts = df[df.labels == \"queen of hearts\"].iloc[0]\n",
    "ace_of_spades = df[df.labels == \"ace of spades\"].iloc[0]\n",
    "print(f'{queen_of_hearts=} \\n  {ace_of_spades=}')\n",
    "\n",
    "IMG_SIZE = 128\n",
    "transform_image = transforms.Compose([\n",
    "    #transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0., 0., 0.), (1., 1., 1.))\n",
    "])\n",
    "\n",
    "img_path = DATA_DIR + queen_of_hearts.filepaths\n",
    "imgQH = Image.open(img_path)\n",
    "imgQH = transform_image(imgQH)\n",
    "img_path = DATA_DIR + ace_of_spades.filepaths\n",
    "imgAS = Image.open(img_path)\n",
    "imgAS = transform_image(imgAS)\n",
    "\n",
    "h = plt.figure(figsize=(10,4))\n",
    "h.add_subplot(1,2,1)\n",
    "plt.imshow(imgQH.permute(1,2,0))\n",
    "plt.axis(\"off\")\n",
    "h.add_subplot(1,2,2)\n",
    "plt.imshow(imgAS.permute(1,2,0))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "imgTensor = torch.stack((imgQH, imgAS), dim=0)\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=1, padding=1, bias=False, padding_mode=\"replicate\")\n",
    "state_dict = conv2d.state_dict()\n",
    "print(f'{state_dict=}')\n",
    "print(state_dict['weight'].shape)\n",
    "\n",
    "sobelGx = torch.tensor([[1, 0 , -1],\n",
    "                        [2, 0, -2],\n",
    "                        [1, 0 , -1]], requires_grad=False, dtype=torch.float32)\n",
    "\n",
    "sobelGy = torch.tensor([[1, 2 , 1],\n",
    "                        [0, 0, 0],\n",
    "                        [-1, -2 , -1]], requires_grad=False, dtype=torch.float32)\n",
    "\n",
    "sobelGx = sobelGx / 4.0\n",
    "sobelGy = sobelGy / 4.0\n",
    "\n",
    "filterQH_Gx = torch.stack((sobelGx, torch.zeros((3,3)), torch.zeros((3,3))), dim=0)\n",
    "filterQH_Gy = torch.stack((sobelGy, torch.zeros((3,3)), torch.zeros((3,3))), dim=0)\n",
    "filterAS_Gx = torch.stack((sobelGx/3, sobelGx/3, sobelGx/3), dim=0)\n",
    "filterAS_Gy = torch.stack((sobelGy/3, sobelGy/3, sobelGy/3), dim=0)\n",
    "\n",
    "print(f'{filterQH_Gy=}')\n",
    "weightTensor = torch.stack((filterQH_Gx, filterQH_Gy, filterAS_Gx, filterAS_Gy ), dim=0)\n",
    "print(f'{weightTensor=} {weightTensor.shape=}')\n",
    "\n",
    "state_dict = conv2d.state_dict()\n",
    "state_dict[\"weight\"] = weightTensor\n",
    "conv2d.load_state_dict(state_dict)\n",
    "\n",
    "result = conv2d(imgTensor)\n",
    "print(result.shape)\n",
    "\n",
    "h = plt.figure(figsize=(14,10))\n",
    "k = 0\n",
    "for i in range(0, result.shape[0]):\n",
    "    for j in range(0, result.shape[1]):\n",
    "        k+=1\n",
    "        min = torch.min(result[i][j])\n",
    "        max = torch.max(result[i][j])\n",
    "        print(f'{min=} {max=}')\n",
    "        h.add_subplot(result.shape[0],result.shape[1],k)\n",
    "        print(result[i][j].shape)\n",
    "        plt.imshow(result[i][j].detach().numpy(), vmin=-1, vmax=1, cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

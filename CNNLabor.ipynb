{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b61292f",
   "metadata": {},
   "source": [
    "## 12. Modellparameter und SVD\n",
    "Wir analysieren die Gewichtsmatrix der letzten Schicht mit SVD und zeigen die Form und Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotParameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9afb3",
   "metadata": {},
   "source": [
    "## 11. Filter nach Training visualisieren\n",
    "Wir plotten die Filtergewichte nach dem Training erneut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracyValue = train_accuracy_list[-1]\n",
    "print(f'{train_accuracyValue=}')\n",
    "validation_accuracyValue = validation_accuracy_list[-1]\n",
    "print(f'{validation_accuracyValue=}')\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(loss_list,color=color)\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('total loss',color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color)  \n",
    "ax2.plot( train_accuracy_list, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()\n",
    "color = 'tab:orange'\n",
    "ax2.plot( validation_accuracy_list, color=color)\n",
    "color = 'tab:purple'\n",
    "ax2.plot( validation_loss_list, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb7cc6",
   "metadata": {},
   "source": [
    "## 10. Trainings- und Validierungsmetriken visualisieren\n",
    "Wir plotten die Loss- und Accuracy-Werte für Training und Validierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(n_epochs):\n",
    "    print(f\"n_epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_func, optimizer)\n",
    "    validate(validation_loader, model, loss_func)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330590e",
   "metadata": {},
   "source": [
    "## 9. Training und Validierung durchführen\n",
    "Wir trainieren das Modell und validieren es nach jeder Epoche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "train_accuracy_list = []\n",
    "N_train = len(train_dataset)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss, correct = 0, 0\n",
    "    for batchNr, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        _, yhat = torch.max(pred.data, 1)\n",
    "        correct += (yhat == y).sum().item()\n",
    "        train_loss += loss\n",
    "        if batchNr % 100 == 0:\n",
    "            loss, current = loss.item(), (batchNr + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    accuracy = correct / N_train\n",
    "    train_accuracy_list.append(accuracy)\n",
    "    loss_list.append(train_loss.item()/size)\n",
    "\n",
    "validation_loss_list = []\n",
    "validation_accuracy_list = []\n",
    "N_valid = len(validation_dataset)\n",
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    validation_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    validation_loss /= num_batches\n",
    "    accuracy = correct / N_valid\n",
    "    validation_accuracy_list.append(accuracy)\n",
    "    validation_loss_list.append(validation_loss)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77472eab",
   "metadata": {},
   "source": [
    "## 8. Trainings- und Validierungsfunktionen\n",
    "Wir definieren die Trainings- und Validierungsfunktionen für das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True, num_workers=1)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=500, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a86f5",
   "metadata": {},
   "source": [
    "## 7. Trainingsparameter und DataLoader\n",
    "Wir definieren die Trainingsparameter, den Optimierer, die Loss-Funktion und die DataLoader für Training und Validierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5496e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotParameters(model): \n",
    "    W = model.state_dict()['conv1.0.weight'].data.cpu()\n",
    "    w_min = W.min().item()\n",
    "    w_max = W.max().item()\n",
    "    fig, axes = plt.subplots(3, 6)\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < 16:\n",
    "            ax.set_xlabel(f\"Filter: {i}\")\n",
    "            ax.imshow(W[i, :].view(5, 5), vmin=w_min, vmax=w_max, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if i in range(16,18):\n",
    "            ax.axis('off')\n",
    "    plt.show()\n",
    "PlotParameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be650f1",
   "metadata": {},
   "source": [
    "## 6. Filtergewichte visualisieren\n",
    "Wir plotten die Filtergewichte der ersten Convolution-Schicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device != \"cuda\":\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f'{device=}')\n",
    "model = CNN().to(device)\n",
    "print(\"Print the model:\\n \", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85801bc8",
   "metadata": {},
   "source": [
    "## 5. Gerät wählen (CPU/GPU) und Modell erstellen\n",
    "Wir wählen das Gerät (CPU/GPU/MPS) und initialisieren das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd41b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.out = nn.Linear(32*7*7, 10)\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        pred = self.out(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c96e90",
   "metadata": {},
   "source": [
    "## 4. CNN-Modell definieren\n",
    "Wir definieren die Architektur des Convolutional Neural Networks (CNN) mit zwei Convolution-Schichten und einer voll verbundenen Schicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c597be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().squeeze(), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d7a32",
   "metadata": {},
   "source": [
    "## 3. Beispielbild anzeigen\n",
    "Wir definieren eine Funktion, um ein Beispielbild aus dem Datensatz darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af3d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dataset:\\n \", train_dataset)\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the validating dataset:\\n \", validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0b8e6",
   "metadata": {},
   "source": [
    "## 2. MNIST Datensätze laden\n",
    "Wir laden den Trainings- und Validierungsdatensatz und zeigen deren Eigenschaften."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db2902",
   "metadata": {},
   "source": [
    "## 1. Bibliotheken importieren\n",
    "Wir importieren die benötigten Bibliotheken für das Training und die Visualisierung."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9047cc4",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) mit PyTorch für MNIST\n",
    "Dieses Notebook zeigt, wie man ein einfaches CNN mit PyTorch für die Klassifikation des MNIST-Datensatzes erstellt, trainiert und auswertet."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
